import os
import argparse
import torch
import yaml
import numpy as np
import scanpy as sc
import matplotlib.pyplot as plt

# å¼•å…¥æ¨¡å‹
from sf_model.model.bio_sfinet import BioSFINet

def load_config(config_path="configs/config_human.yaml"):
    with open(config_path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def parse_args():
    parser = argparse.ArgumentParser(description="Evaluate Bio-SFINet & Plot UMAP/Spatial")
    parser.add_argument("--config", default="configs/config_human.yaml", help="Path to YAML config file")
    # é»˜è®¤ä½¿ç”¨ bestï¼Œä¹Ÿå¯ä»¥æŒ‡å®š final
    parser.add_argument("--checkpoint", default="best", choices=["best", "final"], help="Which checkpoint to use (best/final)")
    parser.add_argument("--resolution", type=float, default=0.5, help="Leiden clustering resolution")
    return parser.parse_args()

def visualize_and_save(z_final, coords, save_dir, resolution=0.5):
    """
    ä½¿ç”¨ Scanpy è¿›è¡Œé™ç»´ã€èšç±»å’Œç»˜å›¾
    z_final: [N, C] æœ€ç»ˆçš„èåˆç‰¹å¾ (Tensor or Numpy)
    coords: [N, 2] ç©ºé—´åæ ‡
    """
    print(f"\nğŸ¨ Starting Visualization (Leiden Res={resolution})...")
    
    # ç¡®ä¿è½¬ä¸º numpy
    if isinstance(z_final, torch.Tensor):
        z_final = z_final.cpu().numpy()
    if isinstance(coords, torch.Tensor):
        coords = coords.cpu().numpy()

    # 1. æ„å»º AnnData
    adata = sc.AnnData(X=z_final)
    adata.obsm['spatial'] = coords
    
    # 2. åŸºç¡€åˆ†ææµç¨‹ (Neighbors -> UMAP -> Leiden)
    print("   -> Computing Neighbors...")
    sc.pp.neighbors(adata, use_rep='X')
    
    print("   -> Computing UMAP...")
    sc.tl.umap(adata)
    
    print(f"   -> Clustering (Leiden)...")
    try:
        sc.tl.leiden(adata, resolution=resolution, key_added='cluster')
    except Exception as e:
        print("   âš ï¸ Leiden clustering failed (maybe install leidenalg?), falling back to louvain.")
        sc.tl.louvain(adata, resolution=resolution, key_added='cluster')
    
    # 3. ç»˜å›¾ (UMAP + Spatial)
    # è®¾ç½®ç»˜å›¾é£æ ¼
    sc.set_figure_params(dpi=150, figsize=(6, 6))
    
    print("   -> Plotting...")
    fig, axs = plt.subplots(1, 2, figsize=(14, 6))
    
    # å·¦å›¾: UMAP
    sc.pl.umap(
        adata, 
        color='cluster', 
        ax=axs[0], 
        show=False, 
        title='Bio-SFINet Joint Embedding (UMAP)',
        legend_loc='on data',
        frameon=False,
        size=20
    )
    
    # å³å›¾: Spatial (ç‰©ç†ç©ºé—´)
    sc.pl.embedding(
        adata, 
        basis='spatial', 
        color='cluster', 
        ax=axs[1], 
        show=False, 
        title='Spatial Map',
        size=40, # ç‚¹çš„å¤§å°ï¼Œå¯æ ¹æ®ç»†èƒå¯†åº¦è°ƒæ•´
        frameon=False
    )
    # ç¿»è½¬ Y è½´ä»¥åŒ¹é…å¸¸è§çš„æ˜¾å¾®é•œè§†è§’ (å¯é€‰)
    # axs[1].invert_yaxis() 
    
    # 4. ä¿å­˜å›¾ç‰‡
    # å¦‚æœ save_dir æ˜¯ checkpoints ç›®å½•ï¼Œæˆ‘ä»¬æŠŠå›¾å­˜åˆ°ä¸Šçº§çš„ figures ç›®å½•
    if save_dir.rstrip('/').endswith('checkpoints'):
        base_dir = os.path.dirname(save_dir.rstrip('/'))
        fig_dir = os.path.join(base_dir, "figures")
    else:
        fig_dir = os.path.join(save_dir, "figures")
        
    os.makedirs(fig_dir, exist_ok=True)
    plot_path = os.path.join(fig_dir, "spatial_analysis.pdf")
    
    plt.tight_layout()
    plt.savefig(plot_path, dpi=300)
    plt.close()
    
    print(f"âœ… Plots saved to: {plot_path}")
    
    # 5. ä¿å­˜ç»“æœ h5ad (æ–¹ä¾¿åç»­è‡ªå®šä¹‰åˆ†æ)
    pred_dir = os.path.join(os.path.dirname(fig_dir), "predictions")
    os.makedirs(pred_dir, exist_ok=True)
    h5ad_path = os.path.join(pred_dir, "embedding_joint.h5ad")
    adata.write(h5ad_path)
    print(f"âœ… Embedding h5ad saved to: {h5ad_path}")

def main():
    print("ğŸš€ [Phase 3] Starting Evaluation & Plotting...")
    args = parse_args()
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"   Using device: {device}")

    # 1. åŠ è½½é…ç½®
    config = load_config(args.config)
    processed_dir = config['data']['processed_path']
    save_dir = config['project']['save_dir']
    
    # 2. åŠ è½½æ•°æ® (ç›´æ¥è¯»é¢„å¤„ç†å¥½çš„ Tensor)
    data_path = os.path.join(processed_dir, "processed_data.pt")
    if not os.path.exists(data_path):
        print(f"âŒ Error: Data not found at {data_path}")
        print("   -> Please run 'python run_preprocess.py' first.")
        return

    print(f"\nğŸ“¦ Loading data from {data_path}...")
    data_dict = torch.load(data_path, map_location='cpu')
    
    # æå– Tensor å¹¶è½¬åˆ° GPU
    rna_feat = data_dict["rna_feat"].to(device)
    atac_feat = data_dict["atac_feat"].to(device)
    coords = data_dict["coords"].to(device)
    edge_index = data_dict["edge_index"].to(device)
    u_basis = data_dict["u_basis"].to(device)
    atac_dim = data_dict["atac_dim"]

    # 3. åˆå§‹åŒ–æ¨¡å‹
    print("\nğŸ§  Initializing Bio-SFINet...")
    model = BioSFINet(config, atac_dim=atac_dim).to(device)
    
    # 4. åŠ è½½æƒé‡
    ckpt_name = "ckpt_best.pth" if args.checkpoint == "best" else "model_final.pth"
    ckpt_path = os.path.join(save_dir, ckpt_name)
    
    if not os.path.exists(ckpt_path):
        print(f"âŒ Error: Checkpoint not found at {ckpt_path}")
        print("   -> Please train the model first using 'run_train.py'")
        return
        
    print(f"   -> Loading weights from {ckpt_path}...")
    # åŠ è½½å‚æ•° (å¤„ç†å¯èƒ½çš„ key ä¸åŒ¹é…é—®é¢˜)
    state_dict = torch.load(ckpt_path, map_location=device)
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    
    # 5. æ¨ç† (Inference)
    print("\nğŸ”® Running Inference...")
    with torch.no_grad():
        # Forward pass
        # è¿”å›å€¼: z_rna, z_atac, p_rna, p_atac, rec_rna, rec_atac
        outputs = model(rna_feat, atac_feat, edge_index, u_basis)
        z_rna = outputs[0]
        z_atac = outputs[1]
        
        # èåˆç­–ç•¥: æ‹¼æ¥ (Concatenation)
        # å°†åŒå¡”ç‰¹å¾æ‹¼åœ¨ä¸€èµ·ä½œä¸ºæœ€ç»ˆçš„ç»†èƒè¡¨è¾¾
        z_final = torch.cat([z_rna, z_atac], dim=1)
        
    print(f"   -> Extracted Latent Shape: {z_final.shape}")
    
    # 6. å¯è§†åŒ–
    visualize_and_save(
        z_final, 
        coords, 
        save_dir, 
        resolution=args.resolution
    )
    
    print("\nğŸ‰ Evaluation Complete!")

if __name__ == "__main__":
    main()